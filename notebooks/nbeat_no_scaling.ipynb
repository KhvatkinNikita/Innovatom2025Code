{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISLA: Tenerife, WINDOW = 5\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=False)\n",
      "     | -- GenericBlock(units=128, thetas_dim=4, backcast_length=5, forecast_length=1, share_thetas=False) at @5917719968\n",
      "     | -- GenericBlock(units=128, thetas_dim=4, backcast_length=5, forecast_length=1, share_thetas=False) at @6421521344\n",
      "     | -- GenericBlock(units=128, thetas_dim=4, backcast_length=5, forecast_length=1, share_thetas=False) at @6421519952\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=False)\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=5, forecast_length=1, share_thetas=False) at @6416070608\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=5, forecast_length=1, share_thetas=False) at @6421519088\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=5, forecast_length=1, share_thetas=False) at @6421518656\n",
      "Evaluation Metrics:\n",
      "R2: 0.6171328278203579\n",
      "MAE: 149.9233\n",
      "MSE: 66119.4536\n",
      "RMSE: 257.1370\n",
      "R2: 0.6171\n",
      "MAPE: 0.0176\n",
      "sMAPE: 0.0175\n",
      "\n",
      "\n",
      "ISLA: Tenerife, WINDOW = 6\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=False)\n",
      "     | -- GenericBlock(units=128, thetas_dim=4, backcast_length=6, forecast_length=1, share_thetas=False) at @13187275840\n",
      "     | -- GenericBlock(units=128, thetas_dim=4, backcast_length=6, forecast_length=1, share_thetas=False) at @13201163040\n",
      "     | -- GenericBlock(units=128, thetas_dim=4, backcast_length=6, forecast_length=1, share_thetas=False) at @13199900352\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=False)\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=6, forecast_length=1, share_thetas=False) at @13197354496\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=6, forecast_length=1, share_thetas=False) at @13201542368\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=6, forecast_length=1, share_thetas=False) at @13201544576\n",
      "Evaluation Metrics:\n",
      "R2: 0.5056931854543096\n",
      "MAE: 210.0658\n",
      "MSE: 85364.5830\n",
      "RMSE: 292.1722\n",
      "R2: 0.5057\n",
      "MAPE: 0.0245\n",
      "sMAPE: 0.0244\n",
      "\n",
      "\n",
      "ISLA: Tenerife, WINDOW = 7\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=False)\n",
      "     | -- GenericBlock(units=128, thetas_dim=4, backcast_length=7, forecast_length=1, share_thetas=False) at @6416070608\n",
      "     | -- GenericBlock(units=128, thetas_dim=4, backcast_length=7, forecast_length=1, share_thetas=False) at @6421520096\n",
      "     | -- GenericBlock(units=128, thetas_dim=4, backcast_length=7, forecast_length=1, share_thetas=False) at @13201448720\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=False)\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=7, forecast_length=1, share_thetas=False) at @6421513856\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=7, forecast_length=1, share_thetas=False) at @6421518752\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=7, forecast_length=1, share_thetas=False) at @6421518320\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 98\u001b[39m\n\u001b[32m     96\u001b[39m model.eval()\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     _, val_output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_sequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m     val_loss = criterion(val_output, val_targets)\n\u001b[32m    101\u001b[39m train_losses.append(train_loss.item())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/nbeats_pytorch/model.py:193\u001b[39m, in \u001b[36mNBeatsNet.forward\u001b[39m\u001b[34m(self, backcast)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m stack_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.stacks)):\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m block_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.stacks[stack_id])):\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m         b, f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstacks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstack_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblock_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackcast\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m         backcast = backcast.to(\u001b[38;5;28mself\u001b[39m.device) - b\n\u001b[32m    195\u001b[39m         forecast = forecast.to(\u001b[38;5;28mself\u001b[39m.device) + f\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/nbeats_pytorch/model.py:309\u001b[39m, in \u001b[36mGenericBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    308\u001b[39m     \u001b[38;5;66;03m# no constraint for generic arch.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     x = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGenericBlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m     theta_b = \u001b[38;5;28mself\u001b[39m.theta_b_fc(x)\n\u001b[32m    312\u001b[39m     theta_f = \u001b[38;5;28mself\u001b[39m.theta_f_fc(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/nbeats_pytorch/model.py:256\u001b[39m, in \u001b[36mBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    255\u001b[39m     x = squeeze_last_dim(x)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     x = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    257\u001b[39m     x = F.relu(\u001b[38;5;28mself\u001b[39m.fc2(x))\n\u001b[32m    258\u001b[39m     x = F.relu(\u001b[38;5;28mself\u001b[39m.fc3(x))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/functional.py:1500\u001b[39m, in \u001b[36mrelu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   1498\u001b[39m     result = torch.relu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m     result = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from src.utils import metrics\n",
    "from src.utils import data_loader as d\n",
    "from src.utils import models\n",
    "from src.utils import sliding_window as s\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# Load Data\n",
    "islas_dfs = d.local_data_loader(verbose=False)\n",
    "# Data transform\n",
    "\n",
    "results = {}\n",
    "\n",
    "windows = np.arange(5,20)\n",
    "islas = ['Tenerife', 'Gran Canaria', 'Lanzarote', 'Fuerteventura', 'La Palma', 'La Gomera', 'El Hierro']\n",
    "\n",
    "for isla in islas:\n",
    "    metricas = []\n",
    "    for window in windows:\n",
    "\n",
    "        print(f'ISLA: {isla}, WINDOW = {window}')\n",
    "\n",
    "        # Extract demand value\n",
    "        demand = islas_dfs[isla]['OBS_VALUE'].values.reshape(-1,1) # data['energy'].values.reshape(-1, 1)\n",
    "\n",
    "        # Training and validation\n",
    "        train_size = 1460  # First 4 years for training/validation\n",
    "        val_size = int(0.2 * train_size)  # 20% of training data for validation\n",
    "        window_size = window \n",
    "\n",
    "        # Split into training, validation, and test sets\n",
    "        train_data = demand[:train_size - val_size]\n",
    "        val_data = demand[train_size - val_size:train_size]\n",
    "        test_data = demand[train_size - window_size:]\n",
    "\n",
    "        # Sliding window sequences for training and validation\n",
    "        train_sequences, train_targets = s.create_sequences(train_data, window_size)\n",
    "        val_sequences, val_targets = s.create_sequences(val_data, window_size)\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        train_sequences = torch.tensor(train_sequences, dtype=torch.float32)\n",
    "        train_targets = torch.tensor(train_targets, dtype=torch.float32)\n",
    "        val_sequences = torch.tensor(val_sequences, dtype=torch.float32)\n",
    "        val_targets = torch.tensor(val_targets, dtype=torch.float32)\n",
    "        # Model training and validation\n",
    "        from nbeats_pytorch.model import NBeatsNet \n",
    "\n",
    "        model = NBeatsNet(\n",
    "            stack_types=(\"generic\", \"generic\"),\n",
    "            forecast_length=1,\n",
    "            backcast_length=window_size,\n",
    "            hidden_layer_units=128\n",
    "        )\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "        train_losses, val_losses = [], []\n",
    "        best_val_loss = float('inf')\n",
    "        stopping_counter = 0\n",
    "        early_stopping = True\n",
    "\n",
    "        num_epochs = 20_000 \n",
    "        early_stopping_patience = 1_000\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training step\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            _, output = model(train_sequences)\n",
    "            train_loss = criterion(output, train_targets)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Validation step\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                _, val_output = model(val_sequences)\n",
    "                val_loss = criterion(val_output, val_targets)\n",
    "\n",
    "            train_losses.append(train_loss.item())\n",
    "            val_losses.append(val_loss.item())\n",
    "            if val_loss.item() < best_val_loss:\n",
    "                best_val_loss = val_loss.item()\n",
    "                stopping_counter = 0\n",
    "            else:\n",
    "                stopping_counter += 1\n",
    "\n",
    "            if early_stopping and stopping_counter >= early_stopping_patience:\n",
    "                # print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "            # if (epoch + 1) % 500 == 0:\n",
    "                # print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Val Loss: {val_loss.item():.4f}\\n')\n",
    "\n",
    "\n",
    "        # Prediction\n",
    "        test_sequences, test_targets = s.create_sequences(test_data, window_size)\n",
    "        test_sequences = torch.tensor(test_sequences, dtype=torch.float32)\n",
    "        test_targets = torch.tensor(test_targets, dtype=torch.float32)\n",
    "\n",
    "        # Initialize lists for storing predictions\n",
    "        online_predictions = []\n",
    "        actual_values = []\n",
    "\n",
    "        # Define online optimizer and loss function\n",
    "        online_optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # ======= 9. Online Prediction and Evaluation =======\n",
    "        for i in range(len(test_sequences)):\n",
    "            x = test_sequences[i].unsqueeze(0)\n",
    "\n",
    "            # Model inference\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)[1]  # Extract the forecast output\n",
    "            online_predictions.append(pred.item())\n",
    "            actual_values.append(test_targets[i].item())\n",
    "\n",
    "            # Online learning step\n",
    "            model.train()\n",
    "            online_optimizer.zero_grad()\n",
    "            pred_online = model(x)[1]  # Extract forecast again for training\n",
    "            loss_online = criterion(pred_online, test_targets[i].unsqueeze(0))\n",
    "            loss_online.backward()\n",
    "            online_optimizer.step()\n",
    "\n",
    "\n",
    "        metrics_result = metrics.all_metrics(actual_values, online_predictions)\n",
    "        print(\"Evaluation Metrics:\")\n",
    "        print(f'R2: {metrics_result['R2']}')\n",
    "        for metric, value in metrics_result.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        print('\\n')\n",
    "\n",
    "        # Animation\n",
    "        test_dates = islas_dfs[isla]['TIME_PERIOD_CODE'].values.reshape(-1,1)\n",
    "        metricas.append(metrics_result['R2'])\n",
    "        results[isla] = metricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best window for Tenerife: 9\n",
      "\n",
      "\n",
      "Best window for Gran Canaria: 8\n",
      "\n",
      "\n",
      "Best window for Lanzarote: 8\n"
     ]
    }
   ],
   "source": [
    "for isla in islas:\n",
    "    print(f'\\n\\nBest window for {isla}: {windows[np.argmax(results[isla])]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
